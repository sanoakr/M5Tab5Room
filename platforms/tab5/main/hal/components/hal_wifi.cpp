/*
 * SPDX-FileCopyrightText: 2025 M5Stack Technology CO LTD
 *
 * SPDX-License-Identifier: MIT
 */
#include "hal/hal_esp32.h"
#include <mooncake_log.h>
#include <vector>
#include <memory>
#include <string.h>
#include <math.h>
#include <bsp/m5stack_tab5.h>
#include <freertos/FreeRTOS.h>
#include <freertos/event_groups.h>
#include <esp_wifi.h>
#include <nvs_flash.h>
#include <esp_event.h>
#include <esp_log.h>
#include <nvs_flash.h>
#include <esp_netif.h>
#include <esp_http_server.h>
#include "driver/jpeg_encode.h"
#include "esp_cam_sensor.h"
#include "esp_cam_sensor_detect.h"
#include "sc202cs.h"
#include "esp_video_init.h"
#include "esp_video_device.h"
#include "esp_video_ioctl.h"
#include "linux/videodev2.h"
#include "driver/ppa.h"
#include <fcntl.h>
#include <sys/ioctl.h>
#include <sys/mman.h>
#include <inttypes.h>
#include <esp_pm.h>
#include <esp_sleep.h>

#define TAG "wifi"

// hal_cameraã¨åŒã˜V4L2ã‚«ãƒ¡ãƒ©å®šç¾©
#define EXAMPLE_VIDEO_BUFFER_COUNT 2
#define MEMORY_TYPE                V4L2_MEMORY_MMAP
#define CAM_DEV_PATH               ESP_VIDEO_MIPI_CSI_DEVICE_NAME

#ifndef ARRAY_SIZE
#define ARRAY_SIZE(arr) (sizeof(arr) / sizeof(arr[0]))
#endif

typedef struct cam {
    int fd;
    uint32_t width;
    uint32_t height;
    uint32_t pixel_format;
    uint8_t* buffer[EXAMPLE_VIDEO_BUFFER_COUNT];
} cam_t;

typedef enum {
    EXAMPLE_VIDEO_FMT_RAW8   = V4L2_PIX_FMT_SBGGR8,
    EXAMPLE_VIDEO_FMT_RAW10  = V4L2_PIX_FMT_SBGGR10,
    EXAMPLE_VIDEO_FMT_GREY   = V4L2_PIX_FMT_GREY,
    EXAMPLE_VIDEO_FMT_RGB565 = V4L2_PIX_FMT_RGB565,
    EXAMPLE_VIDEO_FMT_RGB888 = V4L2_PIX_FMT_RGB24,
    EXAMPLE_VIDEO_FMT_YUV422 = V4L2_PIX_FMT_YUV422P,
    EXAMPLE_VIDEO_FMT_YUV420 = V4L2_PIX_FMT_YUV420,
} example_fmt_t;

// ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ç®¡ç†ç”¨
typedef struct {
    char name[64];
    char main_status[128];
    char sub_status[128];
    uint32_t color;
    SemaphoreHandle_t status_mutex;
} status_data_t;

static status_data_t g_status_data = {
    .name = "ã•ã®ã¯ï¼ˆãŠãã‚‰ãï¼‰",
    .main_status = "ä¸åœ¨ã§ã™",
    .sub_status = "ï¼ˆå­¦å¤–ã«ã„ã¾ã™ï¼‰",
    .color = 0xEF5350, // èµ¤è‰²
    .status_mutex = nullptr
};

// ã‚«ãƒ¡ãƒ©ãƒ•ãƒ¬ãƒ¼ãƒ å…±æœ‰ç”¨
typedef struct {
    uint8_t* frame_buffer;
    uint8_t* resize_buffer;  // ãƒªã‚µã‚¤ã‚ºç”¨ãƒãƒƒãƒ•ã‚¡
    size_t frame_size;
    uint32_t width;
    uint32_t height;
    bool frame_ready;
    SemaphoreHandle_t frame_mutex;
    jpeg_encoder_handle_t jpeg_handle;
    uint8_t* jpeg_out_buf;
    size_t jpeg_out_buf_size;
    // ã‚«ãƒ¡ãƒ©è‡ªå‹•å–å¾—ç”¨
    bool auto_capture_enabled;
    int camera_fd;
    uint8_t* auto_frame_buffer;
    size_t auto_frame_buffer_size;
    TaskHandle_t capture_task_handle;
    // ã‚«ãƒ¡ãƒ©ç‹¬ç«‹ç®¡ç†ç”¨
    bool camera_initialized;
    bool camera_running;
    SemaphoreHandle_t camera_control_mutex;
    // å®Ÿéš›ã®ã‚«ãƒ¡ãƒ©ãƒ•ãƒ¬ãƒ¼ãƒ ç®¡ç†ç”¨
    uint8_t* real_camera_buffer;
    uint32_t real_camera_width;
    uint32_t real_camera_height;
    bool real_camera_frame_available;
    uint32_t last_real_frame_time;
    // ç‹¬ç«‹ã‚«ãƒ¡ãƒ©åˆ¶å¾¡ç”¨
    TaskHandle_t direct_camera_task_handle;
    bool direct_camera_enabled;
    uint8_t* direct_camera_frame_buffer;
    size_t direct_camera_frame_size;
    void* camera_device_handle;  // å®Ÿéš›ã®ã‚«ãƒ¡ãƒ©ãƒ‡ãƒã‚¤ã‚¹ãƒãƒ³ãƒ‰ãƒ«
    // V4L2ã‚«ãƒ¡ãƒ©ã‚·ã‚¹ãƒ†ãƒ ç”¨
    cam_t* v4l2_camera;
    bool v4l2_camera_initialized;
    ppa_client_handle_t ppa_handle;
    uint8_t* processed_frame_buffer;
    size_t processed_frame_size;
} camera_frame_t;

static camera_frame_t g_camera_frame = {
    .frame_buffer = nullptr,
    .resize_buffer = nullptr,
    .frame_size = 0,
    .width = 0,
    .height = 0,
    .frame_ready = false,
    .frame_mutex = nullptr,
    .jpeg_handle = nullptr,
    .jpeg_out_buf = nullptr,
    .jpeg_out_buf_size = 0,
    .auto_capture_enabled = false,
    .camera_fd = -1,
    .auto_frame_buffer = nullptr,
    .auto_frame_buffer_size = 0,
    .capture_task_handle = nullptr,
    .camera_initialized = false,
    .camera_running = false,
    .camera_control_mutex = nullptr,
    .real_camera_buffer = nullptr,
    .real_camera_width = 0,
    .real_camera_height = 0,
    .real_camera_frame_available = false,
    .last_real_frame_time = 0,
    .direct_camera_task_handle = nullptr,
    .direct_camera_enabled = false,
    .direct_camera_frame_buffer = nullptr,
    .direct_camera_frame_size = 0,
    .camera_device_handle = nullptr,
    // V4L2ã‚«ãƒ¡ãƒ©ã‚·ã‚¹ãƒ†ãƒ ç”¨
    .v4l2_camera = nullptr,
    .v4l2_camera_initialized = false,
    .ppa_handle = nullptr,
    .processed_frame_buffer = nullptr,
    .processed_frame_size = 0
};

#define WIFI_SSID    "M5Tab5-UserDemo-WiFi"
#define WIFI_PASS    ""
#define MAX_STA_CONN 4
#define JPEG_ENC_QUALITY 60  // é›»åŠ›æ¶ˆè²»è»½æ¸›ã®ãŸã‚å“è³ªã‚’ä¸‹ã’ã‚‹
#define PART_BOUNDARY "123456789000000000000987654321"

// ã‚µãƒãƒ¼ãƒˆã•ã‚Œã‚‹æœ€å¤§è§£åƒåº¦ï¼ˆESP32P4 JPEGã‚¨ãƒ³ã‚³ãƒ¼ãƒ€ãƒ¼ã®åˆ¶é™ï¼‰
// ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ†ãƒ¼ãƒ–ãƒ«ã«åŸºã¥ãæœ€å°å®‰å…¨ã‚µã‚¤ã‚º
#define MAX_ENCODE_WIDTH  320  // 320x240ãŒæœ€å°ã®ã‚µãƒãƒ¼ãƒˆã‚µã‚¤ã‚º
#define MAX_ENCODE_HEIGHT 240  // ã‚¢ã‚¹ãƒšã‚¯ãƒˆæ¯”ã‚’è€ƒæ…®ã—ãŸ240
#define MIN_ENCODE_WIDTH  320  // æœ€å°å¹…ï¼ˆå®‰å…¨ãªå€¤ï¼‰
#define MIN_ENCODE_HEIGHT 240  // æœ€å°é«˜ã•ï¼ˆå®‰å…¨ãªå€¤ï¼‰

// 16ã®å€æ•°ã«èª¿æ•´ã™ã‚‹é–¢æ•°ï¼ˆã‚ˆã‚Šå®‰å…¨ï¼‰
uint32_t align_to_16(uint32_t value) {
    // ESP32P4 JPEG ã‚¨ãƒ³ã‚³ãƒ¼ãƒ€ãƒ¼ã¯ 320x240 ä»¥ä¸Šã‚’æ¨å¥¨
    if (value < MIN_ENCODE_WIDTH && value < MIN_ENCODE_HEIGHT) {
        value = (value < MIN_ENCODE_WIDTH) ? MIN_ENCODE_WIDTH : MIN_ENCODE_HEIGHT;
    }
    return (value + 15) & ~15;
}

// hal_cameraã¨åŒã˜ã‚«ãƒ¡ãƒ©é–‹æ”¾é–¢æ•°
int wifi_video_open(char* dev, example_fmt_t init_fmt)
{
    struct v4l2_format default_format;
    struct v4l2_capability capability;
    const int type = V4L2_BUF_TYPE_VIDEO_CAPTURE;

    int fd = open(dev, O_RDONLY);
    if (fd < 0) {
        ESP_LOGE(TAG, "Open video failed");
        return -1;
    }

    if (ioctl(fd, VIDIOC_QUERYCAP, &capability)) {
        ESP_LOGE(TAG, "failed to get capability");
        goto exit_0;
    }

    ESP_LOGI(TAG, "version: %d.%d.%d", (uint16_t)(capability.version >> 16), (uint8_t)(capability.version >> 8),
             (uint8_t)capability.version);
    ESP_LOGI(TAG, "driver:  %s", capability.driver);
    ESP_LOGI(TAG, "card:    %s", capability.card);
    ESP_LOGI(TAG, "bus:     %s", capability.bus_info);

    memset(&default_format, 0, sizeof(struct v4l2_format));
    default_format.type = type;
    if (ioctl(fd, VIDIOC_G_FMT, &default_format) != 0) {
        ESP_LOGE(TAG, "failed to get format");
        goto exit_0;
    }

    ESP_LOGI(TAG, "width=%" PRIu32 " height=%" PRIu32, default_format.fmt.pix.width, default_format.fmt.pix.height);

    if (default_format.fmt.pix.pixelformat != init_fmt) {
        struct v4l2_format format = {.type = type,
                                     .fmt  = {.pix = {.width       = default_format.fmt.pix.width,
                                                      .height      = default_format.fmt.pix.height,
                                                      .pixelformat = init_fmt}}};

        if (ioctl(fd, VIDIOC_S_FMT, &format) != 0) {
            ESP_LOGE(TAG, "failed to set format");
            goto exit_0;
        }
    }

    return fd;
exit_0:
    close(fd);
    return -1;
}

// hal_cameraã¨åŒã˜ã‚«ãƒ¡ãƒ©æ§‹é€ ä½“åˆæœŸåŒ–é–¢æ•°
static esp_err_t wifi_new_cam(int cam_fd, cam_t** ret_wc)
{
    int ret;
    struct v4l2_format format;
    int type = V4L2_BUF_TYPE_VIDEO_CAPTURE;
    struct v4l2_requestbuffers req;
    cam_t* wc;

    memset(&format, 0, sizeof(struct v4l2_format));
    format.type = V4L2_BUF_TYPE_VIDEO_CAPTURE;
    if (ioctl(cam_fd, VIDIOC_G_FMT, &format) != 0) {
        ESP_LOGE(TAG, "Failed get fmt");
        return ESP_FAIL;
    }

    wc = (cam_t*)malloc(sizeof(cam_t));
    if (!wc) {
        return ESP_ERR_NO_MEM;
    }

    wc->fd           = cam_fd;
    wc->width        = format.fmt.pix.width;
    wc->height       = format.fmt.pix.height;
    wc->pixel_format = format.fmt.pix.pixelformat;

    memset(&req, 0, sizeof(req));
    req.count  = ARRAY_SIZE(wc->buffer);
    req.type   = type;
    req.memory = MEMORY_TYPE;
    if (ioctl(wc->fd, VIDIOC_REQBUFS, &req) != 0) {
        ESP_LOGE(TAG, "failed to req buffers");
        ret = ESP_FAIL;
        goto errout;
    }

    for (int i = 0; i < ARRAY_SIZE(wc->buffer); i++) {
        struct v4l2_buffer buf;

        memset(&buf, 0, sizeof(buf));
        buf.type   = type;
        buf.memory = MEMORY_TYPE;
        buf.index  = i;
        if (ioctl(wc->fd, VIDIOC_QUERYBUF, &buf) != 0) {
            ESP_LOGE(TAG, "failed to query buffer");
            ret = ESP_FAIL;
            goto errout;
        }

        wc->buffer[i] = (uint8_t*)mmap(NULL, buf.length, PROT_READ | PROT_WRITE, MAP_SHARED, wc->fd, buf.m.offset);
        if (!wc->buffer[i]) {
            ESP_LOGE(TAG, "failed to map buffer");
            ret = ESP_FAIL;
            goto errout;
        }

        if (ioctl(wc->fd, VIDIOC_QBUF, &buf) != 0) {
            ESP_LOGE(TAG, "failed to queue frame buffer");
            ret = ESP_FAIL;
            goto errout;
        }
    }

    if (ioctl(wc->fd, VIDIOC_STREAMON, &type)) {
        ESP_LOGE(TAG, "failed to start stream");
        ret = ESP_FAIL;
        goto errout;
    }

    *ret_wc = wc;
    return ESP_OK;

errout:
    free(wc);
    return ret;
}

// ã‚«ãƒ¡ãƒ©ç®¡ç†é–¢æ•°
bool isCameraInitialized() {
    if (g_camera_frame.camera_control_mutex && 
        xSemaphoreTake(g_camera_frame.camera_control_mutex, pdMS_TO_TICKS(100)) == pdTRUE) {
        bool initialized = g_camera_frame.camera_initialized;
        xSemaphoreGive(g_camera_frame.camera_control_mutex);
        return initialized;
    }
    return false;
}

bool isCameraRunning() {
    if (g_camera_frame.camera_control_mutex && 
        xSemaphoreTake(g_camera_frame.camera_control_mutex, pdMS_TO_TICKS(100)) == pdTRUE) {
        bool running = g_camera_frame.camera_running;
        xSemaphoreGive(g_camera_frame.camera_control_mutex);
        return running;
    }
    return false;
}

esp_err_t initServerManagedCamera() {
    ESP_LOGI(TAG, "Initializing server-managed camera hardware");
    
    if (g_camera_frame.camera_control_mutex == nullptr) {
        g_camera_frame.camera_control_mutex = xSemaphoreCreateMutex();
        if (g_camera_frame.camera_control_mutex == nullptr) {
            ESP_LOGE(TAG, "Failed to create camera control mutex");
            return ESP_ERR_NO_MEM;
        }
    }
    
    if (xSemaphoreTake(g_camera_frame.camera_control_mutex, pdMS_TO_TICKS(1000)) == pdTRUE) {
        if (!g_camera_frame.camera_initialized) {
            // ã‚«ãƒ¡ãƒ©ãƒãƒ¼ãƒ‰ã‚¦ã‚§ã‚¢ã‚’ç›´æ¥åˆæœŸåŒ–
            ESP_LOGI(TAG, "Initializing camera hardware directly for server");
            
            // BSPã®ã‚«ãƒ¡ãƒ©ã‚ªã‚·ãƒ¬ãƒ¼ã‚¿ã‚’åˆæœŸåŒ–
            esp_err_t ret = bsp_cam_osc_init();
            if (ret != ESP_OK) {
                ESP_LOGE(TAG, "Failed to initialize camera oscillator: %s", esp_err_to_name(ret));
                xSemaphoreGive(g_camera_frame.camera_control_mutex);
                return ret;
            }
            
            g_camera_frame.camera_initialized = true;
            g_camera_frame.camera_running = true;  // ç›´æ¥å®Ÿè¡ŒçŠ¶æ…‹ã«
            ESP_LOGI(TAG, "Server-managed camera hardware initialized successfully");
            xSemaphoreGive(g_camera_frame.camera_control_mutex);
            return ESP_OK;
        } else {
            ESP_LOGI(TAG, "Server-managed camera already initialized");
            xSemaphoreGive(g_camera_frame.camera_control_mutex);
            return ESP_OK;
        }
    }
    
    ESP_LOGE(TAG, "Failed to acquire camera control mutex");
    return ESP_ERR_TIMEOUT;
}

esp_err_t startServerManagedCamera() {
    ESP_LOGI(TAG, "Starting server-managed camera");
    
    if (xSemaphoreTake(g_camera_frame.camera_control_mutex, pdMS_TO_TICKS(1000)) == pdTRUE) {
        if (g_camera_frame.camera_initialized && !g_camera_frame.camera_running) {
            // ã‚«ãƒ¡ãƒ©ã‚’é–‹å§‹
            g_camera_frame.camera_running = true;
            ESP_LOGI(TAG, "Server-managed camera started");
        } else if (g_camera_frame.camera_running) {
            ESP_LOGI(TAG, "Server-managed camera already running");
        } else {
            ESP_LOGW(TAG, "Camera not initialized, cannot start");
        }
        xSemaphoreGive(g_camera_frame.camera_control_mutex);
        return ESP_OK;
    }
    
    ESP_LOGE(TAG, "Failed to acquire camera control mutex");
    return ESP_ERR_TIMEOUT;
}

// ã‚«ãƒ¡ãƒ©è‡ªå‹•åˆæœŸåŒ–é–¢æ•°
esp_err_t init_auto_camera() {
    ESP_LOGI(TAG, "Initializing auto camera for continuous streaming");
    
    // è‡ªå‹•ãƒ•ãƒ¬ãƒ¼ãƒ ç”Ÿæˆã‚’æœ‰åŠ¹ã«ã™ã‚‹
    g_camera_frame.auto_capture_enabled = true;
    
    // ç‹¬ç«‹ã‚«ãƒ¡ãƒ©åˆ¶å¾¡ã‚’æœ‰åŠ¹ã«ã™ã‚‹
    g_camera_frame.direct_camera_enabled = true;
    
    ESP_LOGI(TAG, "Auto capture enabled - will provide continuous streaming with direct camera control");
    return ESP_OK;
}

// ã‚«ãƒ¡ãƒ©ã®ç‹¬ç«‹åˆ¶å¾¡ã‚¿ã‚¹ã‚¯ï¼ˆhal_cameraã¨åŒã˜V4L2æ–¹å¼ã‚’ä½¿ç”¨ï¼‰
void direct_camera_capture_task(void* param) {
    ESP_LOGI(TAG, "Direct camera capture task started - using V4L2 real camera system");
    
    // ESP32P4ã®V4L2ã‚«ãƒ¡ãƒ©ã‚·ã‚¹ãƒ†ãƒ ã‚’åˆæœŸåŒ–ï¼ˆhal_cameraã¨åŒã˜æ–¹æ³•ï¼‰
    const uint32_t camera_width = 1280;
    const uint32_t camera_height = 720;
    const size_t camera_frame_size = camera_width * camera_height * 2; // RGB565
    
    // ãƒ•ãƒ¬ãƒ¼ãƒ ãƒãƒƒãƒ•ã‚¡ã‚’ç¢ºä¿
    g_camera_frame.direct_camera_frame_buffer = (uint8_t*)heap_caps_malloc(camera_frame_size, MALLOC_CAP_DMA | MALLOC_CAP_SPIRAM);
    if (g_camera_frame.direct_camera_frame_buffer == nullptr) {
        ESP_LOGE(TAG, "Failed to allocate direct camera frame buffer");
        vTaskDelete(NULL);
        return;
    }
    
    // å‡¦ç†æ¸ˆã¿ãƒ•ãƒ¬ãƒ¼ãƒ ãƒãƒƒãƒ•ã‚¡ã‚’ç¢ºä¿
    g_camera_frame.processed_frame_buffer = (uint8_t*)heap_caps_malloc(camera_frame_size, MALLOC_CAP_DMA | MALLOC_CAP_SPIRAM);
    if (g_camera_frame.processed_frame_buffer == nullptr) {
        ESP_LOGE(TAG, "Failed to allocate processed frame buffer");
        heap_caps_free(g_camera_frame.direct_camera_frame_buffer);
        vTaskDelete(NULL);
        return;
    }
    
    g_camera_frame.direct_camera_frame_size = camera_frame_size;
    g_camera_frame.processed_frame_size = camera_frame_size;
    ESP_LOGI(TAG, "Allocated camera frame buffers: %" PRIu32 "x%" PRIu32 ", size=%d bytes", 
            (uint32_t)camera_width, (uint32_t)camera_height, (int)camera_frame_size);
    
    // ESP32P4 Video systemã‚’åˆæœŸåŒ–ï¼ˆhal_cameraã¨åŒã˜æ–¹æ³•ï¼‰
    ESP_LOGI(TAG, "Initializing ESP32P4 V4L2 camera system");
    
    uint32_t frame_counter = 0;  // å¤‰æ•°å®£è¨€ã‚’å‰ã«ç§»å‹•
    struct v4l2_buffer buf;
    
    if (!g_camera_frame.v4l2_camera_initialized) {
        // hal_cameraã¨åŒã˜CSIè¨­å®šã‚’ä½¿ç”¨
        esp_video_init_csi_config_t csi_config = {
            .sccb_config = {
                .init_sccb  = false,
                .i2c_handle = bsp_i2c_get_handle(),
                .freq       = 400000,
            },
            .reset_pin = -1,
            .pwdn_pin  = -1,
        };
        
        esp_video_init_config_t cam_config = {
            .csi  = &csi_config,
            .dvp  = NULL,
            .jpeg = NULL,
            .isp  = NULL
        };
        
        ESP_LOGI(TAG, "Initializing ESP video system...");
        esp_err_t video_init_result = esp_video_init(&cam_config);
        if (video_init_result != ESP_OK) {
            ESP_LOGE(TAG, "Failed to initialize ESP video system: %s", esp_err_to_name(video_init_result));
            goto cleanup;
        }
        
        ESP_LOGI(TAG, "Opening V4L2 camera device: %s", CAM_DEV_PATH);
        int video_cam_fd = wifi_video_open((char*)CAM_DEV_PATH, EXAMPLE_VIDEO_FMT_RGB565);
        if (video_cam_fd < 0) {
            ESP_LOGW(TAG, "Failed to open V4L2 camera device - falling back to simulation mode");
            // ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼šã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ãƒ¢ãƒ¼ãƒ‰ã§ç¶™ç¶š
            g_camera_frame.v4l2_camera_initialized = false;
            g_camera_frame.camera_initialized = true;
            g_camera_frame.camera_running = true;
            goto skip_v4l2_init;
        }
        
        ESP_LOGI(TAG, "Initializing camera structure...");
        esp_err_t cam_init_result = wifi_new_cam(video_cam_fd, &g_camera_frame.v4l2_camera);
        if (cam_init_result != ESP_OK) {
            ESP_LOGE(TAG, "Failed to initialize camera: %s", esp_err_to_name(cam_init_result));
            close(video_cam_fd);
            goto cleanup;
        }
        
        // PPAï¼ˆPicture Processing Acceleratorï¼‰ã‚’åˆæœŸåŒ–
        ppa_client_config_t ppa_config = {
            .oper_type = PPA_OPERATION_SRM,
            .max_pending_trans_num = 1,
            .data_burst_length = PPA_DATA_BURST_LENGTH_128
        };
        esp_err_t ppa_result = ppa_register_client(&ppa_config, &g_camera_frame.ppa_handle);
        if (ppa_result != ESP_OK) {
            ESP_LOGE(TAG, "Failed to register PPA client: %s", esp_err_to_name(ppa_result));
            goto cleanup;
        }
        
        g_camera_frame.v4l2_camera_initialized = true;
        g_camera_frame.camera_initialized = true;
        g_camera_frame.camera_running = true;
        
        ESP_LOGI(TAG, "V4L2 camera system initialized successfully - Real camera ready!");
        ESP_LOGI(TAG, "Camera format: %" PRIu32 "x%" PRIu32 ", pixel_format: 0x%" PRIx32, 
                g_camera_frame.v4l2_camera->width, g_camera_frame.v4l2_camera->height, 
                g_camera_frame.v4l2_camera->pixel_format);
    }
    
skip_v4l2_init:
    
    while (g_camera_frame.direct_camera_enabled && g_camera_frame.camera_running) {
        if (g_camera_frame.v4l2_camera_initialized) {
            // V4L2ã‹ã‚‰å®Ÿéš›ã®ã‚«ãƒ¡ãƒ©ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’å–å¾—
            memset(&buf, 0, sizeof(buf));
            buf.type = V4L2_BUF_TYPE_VIDEO_CAPTURE;
            buf.memory = MEMORY_TYPE;
            
            if (ioctl(g_camera_frame.v4l2_camera->fd, VIDIOC_DQBUF, &buf) != 0) {
                ESP_LOGE(TAG, "Failed to receive video frame from V4L2");
                vTaskDelay(pdMS_TO_TICKS(200)); // ç´„5fps
                continue;
            }
            
            if (g_camera_frame.frame_mutex && xSemaphoreTake(g_camera_frame.frame_mutex, pdMS_TO_TICKS(10)) == pdTRUE) {
                uint32_t time_ms = esp_timer_get_time() / 1000;
                
                // PPAã‚’ä½¿ç”¨ã—ã¦ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’å‡¦ç†ï¼ˆhal_cameraã¨åŒã˜æ–¹æ³•ï¼‰
                ppa_srm_oper_config_t srm_config = {};
                srm_config.in.buffer = g_camera_frame.v4l2_camera->buffer[buf.index];
                srm_config.in.pic_w = 1280;
                srm_config.in.pic_h = 720;
                srm_config.in.block_w = 1280;
                srm_config.in.block_h = 720;
                srm_config.in.block_offset_x = 0;
                srm_config.in.block_offset_y = 0;
                srm_config.in.srm_cm = PPA_SRM_COLOR_MODE_RGB565;
                
                srm_config.out.buffer = g_camera_frame.processed_frame_buffer;
                srm_config.out.buffer_size = g_camera_frame.processed_frame_size;
                srm_config.out.pic_w = 1280;
                srm_config.out.pic_h = 720;
                srm_config.out.block_offset_x = 0;
                srm_config.out.block_offset_y = 0;
                srm_config.out.srm_cm = PPA_SRM_COLOR_MODE_RGB565;
                
                srm_config.rotation_angle = PPA_SRM_ROTATION_ANGLE_180;
                srm_config.scale_x = 1;
                srm_config.scale_y = 1;
                srm_config.mirror_x = true;
                srm_config.mirror_y = false;
                srm_config.rgb_swap = false;
                srm_config.byte_swap = false;
                srm_config.mode = PPA_TRANS_MODE_BLOCKING;
                
                esp_err_t ppa_result = ppa_do_scale_rotate_mirror(g_camera_frame.ppa_handle, &srm_config);
                if (ppa_result == ESP_OK) {
                    // å®Ÿéš›ã®ã‚«ãƒ¡ãƒ©ãƒ•ãƒ¬ãƒ¼ãƒ æƒ…å ±ã‚’è¨­å®š
                    g_camera_frame.real_camera_buffer = g_camera_frame.processed_frame_buffer;
                    g_camera_frame.real_camera_width = camera_width;
                    g_camera_frame.real_camera_height = camera_height;
                    g_camera_frame.real_camera_frame_available = true;
                    g_camera_frame.last_real_frame_time = time_ms;
                    
                    // å…±é€šãƒ•ãƒ¬ãƒ¼ãƒ ãƒãƒƒãƒ•ã‚¡ã«ã‚‚è¨­å®š
                    g_camera_frame.frame_buffer = g_camera_frame.processed_frame_buffer;
                    g_camera_frame.width = camera_width;
                    g_camera_frame.height = camera_height;
                    g_camera_frame.frame_size = camera_frame_size;
                    g_camera_frame.frame_ready = true;
                    
                    frame_counter++;
                    if (frame_counter % 300 == 1) {  // æœ€åˆã¨10ç§’ã”ã¨ã«ãƒ­ã‚°å‡ºåŠ›
                        ESP_LOGI(TAG, "Real V4L2 camera frame #%lu: %" PRIu32 "x%" PRIu32 ", size=%d bytes (ACTUAL CAMERA DATA)", 
                                frame_counter, (uint32_t)camera_width, (uint32_t)camera_height, (int)camera_frame_size);
                    }
                } else {
                    ESP_LOGW(TAG, "PPA processing failed: %s", esp_err_to_name(ppa_result));
                }
                
                xSemaphoreGive(g_camera_frame.frame_mutex);
            }
            
            // V4L2ãƒãƒƒãƒ•ã‚¡ã‚’æˆ»ã™
            if (ioctl(g_camera_frame.v4l2_camera->fd, VIDIOC_QBUF, &buf) != 0) {
                ESP_LOGE(TAG, "Failed to free video frame");
            }
        } else {
            // ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ãƒ¢ãƒ¼ãƒ‰ï¼ˆV4L2ãŒä½¿ç”¨ã§ããªã„å ´åˆï¼‰
            if (g_camera_frame.frame_mutex && xSemaphoreTake(g_camera_frame.frame_mutex, pdMS_TO_TICKS(10)) == pdTRUE) {
                uint32_t time_ms = esp_timer_get_time() / 1000;
                
                // é«˜å“è³ªã‚«ãƒ¡ãƒ©ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³
                uint16_t* pixels = (uint16_t*)g_camera_frame.direct_camera_frame_buffer;
                
                for (uint32_t y = 0; y < camera_height; y++) {
                    for (uint32_t x = 0; x < camera_width; x++) {
                        uint8_t r, g, b;
                        
                        // V4L2å¤±æ•—ã‹ã‚‰ã®ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯è¡¨ç¤º
                        float wave_x = sinf(((float)x / camera_width) * 3.14159f + (float)time_ms / 1000.0f) * 0.3f + 0.7f;
                        float wave_y = cosf(((float)y / camera_height) * 3.14159f + (float)time_ms / 1500.0f) * 0.3f + 0.7f;
                        
                        r = (uint8_t)((wave_x * x * 31) / camera_width);
                        g = (uint8_t)((wave_y * y * 63) / camera_height);
                        b = (uint8_t)(((wave_x + wave_y) * (x + y) * 31) / (camera_width + camera_height));
                        
                        // å¢ƒç•Œãƒã‚§ãƒƒã‚¯
                        r = r > 31 ? 31 : r;
                        g = g > 63 ? 63 : g;
                        b = b > 31 ? 31 : b;
                        
                        // ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹è¡¨ç¤ºï¼šãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ãƒ¢ãƒ¼ãƒ‰
                        if (y >= 50 && y < 150 && x >= 50 && x < 1200) {
                            if ((frame_counter / 100) % 2 == 0) {
                                r = 31; g = 31; b = 0; // é»„è‰²ã§"FALLBACK MODE"
                            } else {
                                r = 31; g = 15; b = 0; // ã‚ªãƒ¬ãƒ³ã‚¸
                            }
                        }
                        
                        pixels[y * camera_width + x] = (r << 11) | (g << 5) | b;
                    }
                }
                
                // ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ãƒ•ãƒ¬ãƒ¼ãƒ æƒ…å ±ã‚’è¨­å®š
                g_camera_frame.real_camera_buffer = g_camera_frame.direct_camera_frame_buffer;
                g_camera_frame.real_camera_width = camera_width;
                g_camera_frame.real_camera_height = camera_height;
                g_camera_frame.real_camera_frame_available = true;
                g_camera_frame.last_real_frame_time = time_ms;
                
                // å…±é€šãƒ•ãƒ¬ãƒ¼ãƒ ãƒãƒƒãƒ•ã‚¡ã«ã‚‚è¨­å®š
                g_camera_frame.frame_buffer = g_camera_frame.direct_camera_frame_buffer;
                g_camera_frame.width = camera_width;
                g_camera_frame.height = camera_height;
                g_camera_frame.frame_size = camera_frame_size;
                g_camera_frame.frame_ready = true;
                
                frame_counter++;
                if (frame_counter % 300 == 1) {  // æœ€åˆã¨10ç§’ã”ã¨ã«ãƒ­ã‚°å‡ºåŠ›
                    ESP_LOGI(TAG, "Fallback simulation frame #%lu: %" PRIu32 "x%" PRIu32 ", size=%d bytes (V4L2 FALLBACK)", 
                            frame_counter, (uint32_t)camera_width, (uint32_t)camera_height, (int)camera_frame_size);
                }
                
                xSemaphoreGive(g_camera_frame.frame_mutex);
            }
        }
        
        vTaskDelay(pdMS_TO_TICKS(200)); // ç´„5fps
    }
    
    ESP_LOGI(TAG, "Direct V4L2 camera capture task ended - total frames: %lu", frame_counter);
    
cleanup:
    // ãƒªã‚½ãƒ¼ã‚¹ã‚’è§£æ”¾
    if (g_camera_frame.ppa_handle) {
        ppa_unregister_client(g_camera_frame.ppa_handle);
        g_camera_frame.ppa_handle = nullptr;
    }
    
    if (g_camera_frame.v4l2_camera) {
        if (g_camera_frame.v4l2_camera->fd >= 0) {
            close(g_camera_frame.v4l2_camera->fd);
        }
        free(g_camera_frame.v4l2_camera);
        g_camera_frame.v4l2_camera = nullptr;
    }
    
    if (g_camera_frame.direct_camera_frame_buffer) {
        heap_caps_free(g_camera_frame.direct_camera_frame_buffer);
        g_camera_frame.direct_camera_frame_buffer = nullptr;
    }
    
    if (g_camera_frame.processed_frame_buffer) {
        heap_caps_free(g_camera_frame.processed_frame_buffer);
        g_camera_frame.processed_frame_buffer = nullptr;
    }
    
    g_camera_frame.v4l2_camera_initialized = false;
    
    vTaskDelete(NULL);
}

// ã‚«ãƒ¡ãƒ©è‡ªå‹•ãƒ•ãƒ¬ãƒ¼ãƒ å–å¾—ã‚¿ã‚¹ã‚¯
void camera_auto_capture_task(void* param) {
    ESP_LOGI(TAG, "Camera auto capture task started - waiting for direct camera frames");
    
    uint32_t frame_counter = 0;
    uint32_t real_frame_count = 0;
    uint32_t wait_count = 0;
    
    while (g_camera_frame.auto_capture_enabled) {
        // ãƒ•ãƒ¬ãƒ¼ãƒ ãƒŸãƒ¥ãƒ¼ãƒ†ãƒƒã‚¯ã‚¹ã‚’å–å¾—
        if (g_camera_frame.frame_mutex && xSemaphoreTake(g_camera_frame.frame_mutex, pdMS_TO_TICKS(50)) == pdTRUE) {
            
            uint32_t current_time = esp_timer_get_time() / 1000;
            
            // ç‹¬ç«‹ã‚«ãƒ¡ãƒ©ã¾ãŸã¯å®Ÿéš›ã®ã‚«ãƒ¡ãƒ©ãƒ•ãƒ¬ãƒ¼ãƒ ãŒåˆ©ç”¨å¯èƒ½ã‹ãƒã‚§ãƒƒã‚¯ï¼ˆ5ç§’ä»¥å†…ã®æ–°ã—ã„ãƒ•ãƒ¬ãƒ¼ãƒ ï¼‰
            if (g_camera_frame.real_camera_frame_available && 
                g_camera_frame.real_camera_buffer != nullptr &&
                (current_time - g_camera_frame.last_real_frame_time) < 5000) {
                
                // ç‹¬ç«‹ã‚«ãƒ¡ãƒ©ã¾ãŸã¯å®Ÿéš›ã®ã‚«ãƒ¡ãƒ©ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’ä½¿ç”¨ï¼ˆæ—¢ã«è¨­å®šæ¸ˆã¿ï¼‰
                // direct_camera_capture_taskãŒæ—¢ã«ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’è¨­å®šã—ã¦ã„ã‚‹
                real_frame_count++;
                
                if (real_frame_count % 600 == 1) {  // æœ€åˆã¨20ç§’ã”ã¨ã«ãƒ­ã‚°å‡ºåŠ›
                    ESP_LOGI(TAG, "Using REAL camera frame #%lu: %" PRIu32 "x%" PRIu32 ", size=%d bytes", 
                            real_frame_count, (uint32_t)g_camera_frame.width, (uint32_t)g_camera_frame.height, (int)g_camera_frame.frame_size);
                }
            } else {
                // ã‚«ãƒ¡ãƒ©ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’å¾…æ©Ÿä¸­
                wait_count++;
                if (wait_count % 300 == 1) {  // æœ€åˆã¨10ç§’ã”ã¨ã«ãƒ­ã‚°å‡ºåŠ›
                    ESP_LOGI(TAG, "Waiting for camera frames... (%lu attempts, last_frame_time=%lu, current=%lu)", 
                            wait_count, g_camera_frame.last_real_frame_time, current_time);
                }
                
                // ãƒ•ãƒ¬ãƒ¼ãƒ ãŒåˆ©ç”¨ã§ããªã„å ´åˆã¯å¾…æ©Ÿï¼ˆãƒ†ã‚¹ãƒˆãƒ‘ã‚¿ãƒ¼ãƒ³ã¯ç”Ÿæˆã—ãªã„ï¼‰
                g_camera_frame.frame_ready = false;
            }
            
            frame_counter++;
            
            // çµ±è¨ˆæƒ…å ±ã‚’å®šæœŸçš„ã«å‡ºåŠ›
            if (frame_counter % 1800 == 0) {  // 60ç§’ã”ã¨
                ESP_LOGI(TAG, "Streaming stats: Real camera frames: %lu, Wait attempts: %lu", 
                        real_frame_count, wait_count);
            }
            
            xSemaphoreGive(g_camera_frame.frame_mutex);
        }
        
        vTaskDelay(pdMS_TO_TICKS(200)); // ç´„5fps
    }
    
    ESP_LOGI(TAG, "Camera auto capture task ended - final stats: Real camera: %lu, Wait attempts: %lu", 
            real_frame_count, wait_count);
    vTaskDelete(NULL);
}

// RGB565ç”»åƒã‚’ãƒªã‚µã‚¤ã‚ºã™ã‚‹é–¢æ•°ï¼ˆãƒ‹ã‚¢ãƒ¬ã‚¹ãƒˆãƒã‚¤ãƒãƒ¼æ³•ï¼‰
esp_err_t resize_rgb565_image(uint8_t* src_buf, uint32_t src_width, uint32_t src_height,
                              uint8_t* dst_buf, uint32_t dst_width, uint32_t dst_height) {
    if (!src_buf || !dst_buf || src_width == 0 || src_height == 0 || dst_width == 0 || dst_height == 0) {
        return ESP_ERR_INVALID_ARG;
    }
    
    uint16_t* src_pixels = (uint16_t*)src_buf;
    uint16_t* dst_pixels = (uint16_t*)dst_buf;
    
    // ã‚¹ã‚±ãƒ¼ãƒ«ä¿‚æ•°ã‚’è¨ˆç®—
    float x_scale = (float)src_width / dst_width;
    float y_scale = (float)src_height / dst_height;
    
    for (uint32_t dst_y = 0; dst_y < dst_height; dst_y++) {
        for (uint32_t dst_x = 0; dst_x < dst_width; dst_x++) {
            // ã‚½ãƒ¼ã‚¹ç”»åƒã§ã®å¯¾å¿œã™ã‚‹åº§æ¨™ã‚’è¨ˆç®—
            uint32_t src_x = (uint32_t)(dst_x * x_scale);
            uint32_t src_y = (uint32_t)(dst_y * y_scale);
            
            // å¢ƒç•Œãƒã‚§ãƒƒã‚¯
            if (src_x >= src_width) src_x = src_width - 1;
            if (src_y >= src_height) src_y = src_height - 1;
            
            // ãƒ”ã‚¯ã‚»ãƒ«ã‚’ã‚³ãƒ”ãƒ¼
            uint32_t src_idx = src_y * src_width + src_x;
            uint32_t dst_idx = dst_y * dst_width + dst_x;
            dst_pixels[dst_idx] = src_pixels[src_idx];
        }
    }
    
    return ESP_OK;
}

// ã‚«ãƒ¡ãƒ©ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ç”¨HTTPãƒãƒ³ãƒ‰ãƒ©ï¼ˆãƒ†ã‚¹ãƒˆãƒ‘ã‚¿ãƒ¼ãƒ³ã®ã¿ï¼‰
esp_err_t camera_stream_handler(httpd_req_t* req)
{
    ESP_LOGI(TAG, "Test pattern stream handler started - NO REAL CAMERA");
    
    // ç°¡å˜ãªãƒ†ã‚¹ãƒˆãƒ‘ã‚¿ãƒ¼ãƒ³HTMLã‚’è¿”ã™
    const char* test_pattern_html = R"(
        <!DOCTYPE html>
        <html>
        <head>
            <meta charset="UTF-8">
            <title>Camera Disabled</title>
            <style>
                body { 
                    font-family: Arial, sans-serif; 
                    text-align: center; 
                    margin: 50px; 
                    background-color: #f0f0f0; 
                }
                .message {
                    background: #fff;
                    border: 2px solid #333;
                    border-radius: 10px;
                    padding: 30px;
                    margin: 20px auto;
                    max-width: 600px;
                }
                .pattern {
                    width: 320px;
                    height: 240px;
                    background: linear-gradient(45deg, #ff6b6b, #4ecdc4, #45b7d1, #f9ca24);
                    margin: 20px auto;
                    border: 2px solid #333;
                    animation: colorShift 3s ease-in-out infinite alternate;
                }
                @keyframes colorShift {
                    0% { filter: hue-rotate(0deg); }
                    100% { filter: hue-rotate(360deg); }
                }
            </style>
        </head>
        <body>
            <div class="message">
                <h1>ğŸ“· ã‚«ãƒ¡ãƒ©ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ç„¡åŠ¹</h1>
                <p>ã‚«ãƒ¡ãƒ©ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°æ©Ÿèƒ½ã¯ç„¡åŠ¹åŒ–ã•ã‚Œã¦ã„ã¾ã™ã€‚</p>
                <p>ãƒªã‚¢ãƒ«ã‚«ãƒ¡ãƒ©ã®ä»£ã‚ã‚Šã«ãƒ†ã‚¹ãƒˆãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’è¡¨ç¤ºä¸­ã§ã™ã€‚</p>
                <div class="pattern"></div>
                <p><small>Camera streaming has been disabled by user request</small></p>
            </div>
        </body>
        </html>
    )";
    
    httpd_resp_set_type(req, "text/html");
    httpd_resp_send(req, test_pattern_html, HTTPD_RESP_USE_STRLEN);
    
    ESP_LOGI(TAG, "Test pattern HTML sent - camera streaming disabled");
    return ESP_OK;
}

// ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹æ›´æ–°API
esp_err_t status_api_handler(httpd_req_t* req)
{
    if (g_status_data.status_mutex && xSemaphoreTake(g_status_data.status_mutex, pdMS_TO_TICKS(100)) == pdTRUE) {
        char json_response[512];
        snprintf(json_response, sizeof(json_response), 
                "{"
                "\"name\":\"%s\","
                "\"main_status\":\"%s\","
                "\"sub_status\":\"%s\","
                "\"color\":\"#%06" PRIX32 "\""
                "}", 
                g_status_data.name, 
                g_status_data.main_status, 
                g_status_data.sub_status,
                g_status_data.color);
        
        xSemaphoreGive(g_status_data.status_mutex);
        
        httpd_resp_set_type(req, "application/json");
        httpd_resp_set_hdr(req, "Access-Control-Allow-Origin", "*");
        httpd_resp_send(req, json_response, HTTPD_RESP_USE_STRLEN);
        return ESP_OK;
    }
    
    httpd_resp_send_err(req, HTTPD_500_INTERNAL_SERVER_ERROR, "Status mutex error");
    return ESP_FAIL;
}

// HTTP å¤„ç†å‡½æ•°
esp_err_t hello_get_handler(httpd_req_t* req)
{
    const char* html_response = R"rawliteral(
        <!DOCTYPE html>
        <html>
        <head>
            <meta charset="UTF-8">
            <meta name="viewport" content="width=device-width, initial-scale=1.0">
            <title>M5Stack TAB5 Streaming RoomSign</title>
            <style>
                body {
                    display: flex;
                    flex-direction: column;
                    justify-content: center;
                    align-items: center;
                    height: 100vh;
                    margin: 0;
                    font-family: sans-serif;
                    background-color: #f0f0f0;
                }
                h1 {
                    font-size: 48px;
                    color: #333;
                    margin: 0;
                }
                p {
                    font-size: 18px;
                    color: #666;
                    margin-top: 10px;
                }
                .stream-container {
                    display: flex;
                    flex-direction: column;
                    align-items: center;
                    justify-content: center;
                    margin-top: 32px;
                    background: #fff;
                    border-radius: 16px;
                    box-shadow: 0 2px 12px rgba(0,0,0,0.08);
                    padding: 24px 32px;
                }
                #camera-stream {
                    max-width: 90vw;
                    max-height: 60vh;
                    border: 2px solid #333;
                    border-radius: 8px;
                    background: #222;
                    display: block;
                    margin-bottom: 16px;
                }
                .toggle-switch {
                    position: relative;
                    display: inline-block;
                    width: 80px;
                    height: 40px;
                    background-color: #ccc;
                    border-radius: 20px;
                    cursor: pointer;
                    transition: background-color 0.3s ease;
                }
                .toggle-switch.active {
                    background-color: #1976d2;
                }
                .toggle-slider {
                    position: absolute;
                    top: 2px;
                    left: 2px;
                    width: 36px;
                    height: 36px;
                    background-color: white;
                    border-radius: 50%;
                    transition: left 0.3s ease;
                    box-shadow: 0 2px 4px rgba(0,0,0,0.2);
                }
                .toggle-switch.active .toggle-slider {
                    left: 42px;
                }
                .toggle-label {
                    margin-bottom: 8px;
                    font-size: 14px;
                    color: #333;
                    text-align: center;
                }
                .status-display {
                    margin-top: 32px;
                    padding: 24px 32px;
                    background: #fff;
                    border-radius: 16px;
                    box-shadow: 0 2px 12px rgba(0,0,0,0.08);
                    text-align: center;
                    max-width: 600px;
                }
                .status-name {
                    font-size: 20px;
                    color: #666;
                    margin-bottom: 16px;
                }
                .status-main {
                    font-size: 48px;
                    font-weight: bold;
                    margin-bottom: 12px;
                    color: #EF5350;
                }
                .status-sub {
                    font-size: 24px;
                    color: #666;
                }
            </style>
            <script>
                function toggleStream() {
                    // ã‚«ãƒ¡ãƒ©ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ã¯ç„¡åŠ¹åŒ–ã•ã‚Œã¦ã„ã‚‹ãŸã‚ä½•ã‚‚ã—ãªã„
                    console.log('Camera streaming is disabled');
                }
                
                function updateStatus() {
                    fetch('/api/status')
                        .then(response => response.json())
                        .then(data => {
                            document.getElementById('status-name').textContent = data.name;
                            document.getElementById('status-main').textContent = data.main_status;
                            document.getElementById('status-sub').textContent = data.sub_status;
                            document.getElementById('status-main').style.color = data.color;
                            document.getElementById('status-sub').style.color = data.color;
                        })
                        .catch(error => {
                            console.error('Status update error:', error);
                        });
                }
                
                document.addEventListener('DOMContentLoaded', function() {
                    // ã‚«ãƒ¡ãƒ©ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ã¯ç„¡åŠ¹åŒ–ã•ã‚Œã¦ã„ã‚‹ãŸã‚ãƒˆã‚°ãƒ«æ©Ÿèƒ½ãªã—
                    console.log('Camera streaming disabled - no toggle functionality');
                    
                    // Update status every 2 seconds
                    updateStatus();
                    setInterval(updateStatus, 2000);
                });
            </script>
        </head>
        <body>
            <h1>Tab5 RoomSign</h1>
            <p>From M5StackTab5</p>
            <div class="stream-container">
                <div style="width: 320px; height: 240px; border: 2px solid #ff6b6b; border-radius: 8px; background: linear-gradient(45deg, #ff6b6b, #4ecdc4); display: flex; align-items: center; justify-content: center; margin-bottom: 16px;">
                    <div style="text-align: center; color: white; font-weight: bold; text-shadow: 1px 1px 2px rgba(0,0,0,0.7);">
                        ğŸ“· CAMERA DISABLED<br>
                        <small>ã‚«ãƒ¡ãƒ©ç„¡åŠ¹</small>
                    </div>
                </div>
                <div class="toggle-label" style="color: #ff6b6b;">Camera Streaming Disabled</div>
                <div style="font-size: 12px; color: #666; margin-top: 8px;">ãƒªã‚¢ãƒ«ã‚«ãƒ¡ãƒ©ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ã¯ç„¡åŠ¹åŒ–ã•ã‚Œã¦ã„ã¾ã™</div>
            </div>
            <div class="status-display">
                <div id="status-name" class="status-name">ã•ã®ã¯ï¼ˆãŠãã‚‰ãï¼‰</div>
                <div id="status-main" class="status-main">ä¸åœ¨ã§ã™</div>
                <div id="status-sub" class="status-sub">ï¼ˆå­¦å¤–ã«ã„ã¾ã™ï¼‰</div>
            </div>
        </body>
        </html>
    )rawliteral";

    httpd_resp_set_type(req, "text/html");
    httpd_resp_send(req, html_response, HTTPD_RESP_USE_STRLEN);
    return ESP_OK;
}

// URI è·¯ç”±
httpd_uri_t hello_uri = {.uri = "/", .method = HTTP_GET, .handler = hello_get_handler, .user_ctx = nullptr};
httpd_uri_t camera_stream_uri = {.uri = "/stream", .method = HTTP_GET, .handler = camera_stream_handler, .user_ctx = nullptr};
httpd_uri_t status_api_uri = {.uri = "/api/status", .method = HTTP_GET, .handler = status_api_handler, .user_ctx = nullptr};

// å¯åŠ¨ Web Server
httpd_handle_t start_webserver()
{
    httpd_config_t config = HTTPD_DEFAULT_CONFIG();
    config.max_uri_handlers = 8; // ãƒãƒ³ãƒ‰ãƒ©æ•°ã‚’å¢—ã‚„ã™
    httpd_handle_t server = nullptr;

    if (httpd_start(&server, &config) == ESP_OK) {
        httpd_register_uri_handler(server, &hello_uri);
        httpd_register_uri_handler(server, &camera_stream_uri);
        httpd_register_uri_handler(server, &status_api_uri);
        
        // ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ç®¡ç†ç”¨ã®mutexåˆæœŸåŒ–
        if (g_status_data.status_mutex == NULL) {
            g_status_data.status_mutex = xSemaphoreCreateMutex();
        }
        
        // ãƒ•ãƒ¬ãƒ¼ãƒ å…±æœ‰ç”¨ã®mutexåˆæœŸåŒ–
        if (g_camera_frame.frame_mutex == NULL) {
            g_camera_frame.frame_mutex = xSemaphoreCreateMutex();
        }
        
        // ã‚«ãƒ¡ãƒ©æ©Ÿèƒ½ã‚’å®Œå…¨ã«ç„¡åŠ¹åŒ– - ãƒ†ã‚¹ãƒˆãƒ‘ã‚¿ãƒ¼ãƒ³ã®ã¿ä½¿ç”¨
        ESP_LOGI(TAG, "Camera initialization SKIPPED - test pattern mode only");
        ESP_LOGI(TAG, "Real camera streaming disabled by user request");
        
        // JPEGã‚¨ãƒ³ã‚³ãƒ¼ãƒ€ãƒ¼ã‚‚ç„¡åŠ¹åŒ–ï¼ˆãƒ†ã‚¹ãƒˆãƒ‘ã‚¿ãƒ¼ãƒ³ã«ã¯ä¸è¦ï¼‰
        ESP_LOGI(TAG, "JPEG encoder initialization SKIPPED - not needed for test patterns");
        
        // ã‚«ãƒ¡ãƒ©è‡ªå‹•å–å¾—ã‚¿ã‚¹ã‚¯ã‚‚ç„¡åŠ¹åŒ–
        ESP_LOGI(TAG, "Camera auto capture and direct capture tasks DISABLED");
        ESP_LOGI(TAG, "Web streaming will show test patterns only");
    }
    return server;
}

// åˆå§‹åŒ– Wi-Fi AP æ¨¡å¼
void wifi_init_softap()
{
    ESP_ERROR_CHECK(esp_netif_init());
    ESP_ERROR_CHECK(esp_event_loop_create_default());

    esp_netif_create_default_wifi_ap();

    wifi_init_config_t cfg = WIFI_INIT_CONFIG_DEFAULT();
    ESP_ERROR_CHECK(esp_wifi_init(&cfg));

    wifi_config_t wifi_config = {};
    std::strncpy(reinterpret_cast<char*>(wifi_config.ap.ssid), WIFI_SSID, sizeof(wifi_config.ap.ssid));
    std::strncpy(reinterpret_cast<char*>(wifi_config.ap.password), WIFI_PASS, sizeof(wifi_config.ap.password));
    wifi_config.ap.ssid_len       = std::strlen(WIFI_SSID);
    wifi_config.ap.max_connection = MAX_STA_CONN;
    wifi_config.ap.authmode       = WIFI_AUTH_OPEN;

    ESP_ERROR_CHECK(esp_wifi_set_mode(WIFI_MODE_AP));
    ESP_ERROR_CHECK(esp_wifi_set_config(WIFI_IF_AP, &wifi_config));
    ESP_ERROR_CHECK(esp_wifi_start());

    ESP_LOGI(TAG, "Wi-Fi AP started. SSID:%s password:%s", WIFI_SSID, WIFI_PASS);
}

static void wifi_ap_test_task(void* param)
{
    wifi_init_softap();
    
    // ã‚«ãƒ¡ãƒ©ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°æ©Ÿèƒ½ã‚’ç„¡åŠ¹åŒ– - ãƒ†ã‚¹ãƒˆãƒ‘ã‚¿ãƒ¼ãƒ³ã®ã¿ä½¿ç”¨
    ESP_LOGI(TAG, "Camera streaming DISABLED - using test patterns only");
    ESP_LOGI(TAG, "Real camera initialization and streaming are disabled by user request");
    
    start_webserver();
    ESP_LOGI(TAG, "WiFi AP and streaming server started - TEST PATTERN ONLY mode");
    
    ESP_LOGI(TAG, "Camera streaming disabled - web page will show test patterns instead of real camera");

    while (1) {
        vTaskDelay(pdMS_TO_TICKS(1000));
    }
    vTaskDelete(NULL);
}

bool HalEsp32::wifi_init()
{
    mclog::tagInfo(TAG, "wifi init");

    esp_err_t ret = nvs_flash_init();
    if (ret == ESP_ERR_NVS_NO_FREE_PAGES || ret == ESP_ERR_NVS_NEW_VERSION_FOUND) {
        ESP_ERROR_CHECK(nvs_flash_erase());
        ret = nvs_flash_init();
    }
    ESP_ERROR_CHECK(ret);

    xTaskCreate(wifi_ap_test_task, "ap", 8192, nullptr, 5, nullptr);
    return true;
}

void HalEsp32::setExtAntennaEnable(bool enable)
{
    _ext_antenna_enable = enable;
    mclog::tagInfo(TAG, "set ext antenna enable: {}", _ext_antenna_enable);
    bsp_set_ext_antenna_enable(_ext_antenna_enable);
}

bool HalEsp32::getExtAntennaEnable()
{
    return _ext_antenna_enable;
}

void HalEsp32::startWifiAp()
{
    wifi_init();
}

// ã‚«ãƒ¡ãƒ©åœæ­¢ã‚’é€šçŸ¥ã™ã‚‹é–¢æ•°ï¼ˆã‚«ãƒ¡ãƒ©ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã‹ã‚‰å‘¼ã°ã‚Œã‚‹ï¼‰
void notifyCameraStop()
{
    if (g_camera_frame.frame_mutex && xSemaphoreTake(g_camera_frame.frame_mutex, pdMS_TO_TICKS(100)) == pdTRUE) {
        ESP_LOGI(TAG, "Camera stopped notification - switching to fallback test pattern");
        
        // å®Ÿéš›ã®ã‚«ãƒ¡ãƒ©ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’ç„¡åŠ¹åŒ–
        g_camera_frame.real_camera_frame_available = false;
        g_camera_frame.real_camera_buffer = nullptr;
        g_camera_frame.real_camera_width = 0;
        g_camera_frame.real_camera_height = 0;
        g_camera_frame.last_real_frame_time = 0;
        
        // ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ãƒ‘ã‚¿ãƒ¼ãƒ³ã«è‡ªå‹•çš„ã«åˆ‡ã‚Šæ›¿ã‚ã‚‹ï¼ˆcamera_auto_capture_taskãŒå‡¦ç†ï¼‰
        ESP_LOGI(TAG, "Real camera unavailable, auto-task will use fallback pattern");
        
        xSemaphoreGive(g_camera_frame.frame_mutex);
    }
}

// hai_cameraã§ä½¿ç”¨ã™ã‚‹ã‚«ãƒ¡ãƒ©çŠ¶æ…‹ãƒã‚§ãƒƒã‚¯é–¢æ•°
bool shouldInitializeCamera() {
    return !isCameraInitialized();
}

bool shouldStartCamera() {
    return isCameraInitialized() && !isCameraRunning();
}

// hai_cameraã§ã®åˆæœŸåŒ–ï¼ˆå¿…è¦ãªå ´åˆã®ã¿ï¼‰
esp_err_t initCameraIfNeeded() {
    if (shouldInitializeCamera()) {
        ESP_LOGI(TAG, "hai_camera: Camera not initialized by server, initializing...");
        return initServerManagedCamera();
    } else {
        ESP_LOGI(TAG, "hai_camera: Camera already initialized by server");
        return ESP_OK;
    }
}

// hai_cameraã§ã®é–‹å§‹ï¼ˆå¿…è¦ãªå ´åˆã®ã¿ï¼‰
esp_err_t startCameraIfNeeded() {
    if (shouldStartCamera()) {
        ESP_LOGI(TAG, "hai_camera: Camera not running, starting...");
        return startServerManagedCamera();
    } else {
        ESP_LOGI(TAG, "hai_camera: Camera already running");
        return ESP_OK;
    }
}

// hai_cameraãŒé–‰ã˜ã‚‰ã‚Œã¦ã‚‚ä½•ã‚‚ã—ãªã„ï¼ˆã‚«ãƒ¡ãƒ©ã¯åœæ­¢ã—ãªã„ï¼‰
void onHaiCameraClosed() {
    ESP_LOGI(TAG, "hai_camera: Application closed, but keeping camera running for streaming");
    // ã‚«ãƒ¡ãƒ©ã¯åœæ­¢ã—ãªã„ - é…ä¿¡ã‚’ç¶™ç¶š
}

// ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹æ›´æ–°é–¢æ•°ï¼ˆview.cppã‹ã‚‰å‘¼ã°ã‚Œã‚‹ï¼‰
void updateRoomSignStatus(const char* main_status, const char* sub_status, uint32_t color) {
    if (g_status_data.status_mutex && xSemaphoreTake(g_status_data.status_mutex, pdMS_TO_TICKS(100)) == pdTRUE) {
        strncpy(g_status_data.main_status, main_status, sizeof(g_status_data.main_status) - 1);
        g_status_data.main_status[sizeof(g_status_data.main_status) - 1] = '\0';
        
        strncpy(g_status_data.sub_status, sub_status, sizeof(g_status_data.sub_status) - 1);
        g_status_data.sub_status[sizeof(g_status_data.sub_status) - 1] = '\0';
        
        g_status_data.color = color;
        
        xSemaphoreGive(g_status_data.status_mutex);
    ESP_LOGI(TAG, "Room sign status updated: %s - %s (color: #%06" PRIX32 ")", main_status, sub_status, color);
    }
}

// ã‚«ãƒ¡ãƒ©ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ‡ãƒ¼ã‚¿ã‚’æ›´æ–°ã™ã‚‹é–¢æ•°ï¼ˆhai_cameraã‹ã‚‰ã®å‘¼ã³å‡ºã—ç”¨ï¼‰
// æ³¨æ„: ç¾åœ¨ã¯ç‹¬ç«‹ã‚«ãƒ¡ãƒ©åˆ¶å¾¡ã«ã‚ˆã‚Šç„¡åŠ¹åŒ–ã•ã‚Œã¦ã„ã¾ã™
void updateCameraFrameForStreaming(uint8_t* frameBuffer, uint32_t width, uint32_t height)
{
    // hal_cameraã‹ã‚‰ã®ãƒ•ãƒ¬ãƒ¼ãƒ æ›´æ–°ã‚’ç„¡åŠ¹åŒ–
    // ç‹¬ç«‹ã‚«ãƒ¡ãƒ©åˆ¶å¾¡ãŒå¸¸ã«ã‚«ãƒ¡ãƒ©ãƒ‡ãƒ¼ã‚¿ã‚’é…ä¿¡ã™ã‚‹ãŸã‚ã€
    // hal_cameraã‹ã‚‰ã®æ›´æ–°ã¯æ··ä¹±ã‚’é¿ã‘ã‚‹ãŸã‚ã«ç„¡è¦–ã—ã¾ã™
    
    static uint32_t ignored_count = 0;
    ignored_count++;
    if (ignored_count == 1 || ignored_count % 300 == 0) { // æœ€åˆã¨10ç§’ã”ã¨ã«ãƒ­ã‚°å‡ºåŠ›
        ESP_LOGI(TAG, "Ignored hal_camera frame update #%lu: %" PRIu32 "x%" PRIu32 " (using direct camera instead)", 
                ignored_count, width, height);
    }
    
    // ãƒ•ãƒ¬ãƒ¼ãƒ æ›´æ–°ã¯è¡Œã‚ãªã„ï¼ˆdirect_camera_capture_taskãŒç‹¬ç«‹ã—ã¦å‡¦ç†ï¼‰
}
